import pandas as pd
import numpy as np
import random

def generate_realistic_data(num_samples=200):
    """
    Генерує "нормальний" набір реалістичних даних за допомогою
    статистичних методів (numpy.random.multivariate_normal)
    з подальшими нелінійними перетвореннями для реалістичності.
    
    V3.1: Видалено .astype(int) для коректної обробки NaN.
    """
    
    # 1. Визначаємо назви числових змінних
    # 'Вік', 'Лог_Дохід', 'Лог_Витрати', 'Кількість_покупок', 'Час_на_сайті_хв', 'Базова_Оцінка'
    num_vars = 6
    
    # 2. Визначаємо бажані середні значення (means) для кожної змінної
    # Ми генеруємо ЛОГАРИФМИ доходу/витрат, щоб потім їх експоненціювати
    means = [
        40,    # Вік
        10.7,  # Логарифм Доходу (exp(10.7) ~ 44000)
        10.2,  # Логарифм Витрат (exp(10.2) ~ 27000)
        15,    # Кількість_покупок
        60,    # Час_на_сайті_хв
        3.0    # Базова Оцінка (до нелінійного перетворення)
    ]
    
    # 3. Визначаємо бажану МАТРИЦЮ КОРЕЛЯЦІЙ для базових змінних
    corr_matrix = [
        # Вік   ЛогДохід  ЛогВитрати  Покупки  Час_на_сайті  БазОцінка
        [1.00,  0.60,     0.55,       0.50,    0.30,         0.20],  # Вік
        [0.60,  1.00,     0.85,       0.75,    0.60,         0.50],  # ЛогДохід
        [0.55,  0.85,     1.00,       0.70,    0.55,         0.45],  # ЛогВитрати
        [0.50,  0.75,     0.70,       1.00,    0.50,         0.40],  # Кількість_покупок
        [0.30,  0.60,     0.55,       0.50,    1.00,         0.65],  # Час_на_сайті_хв
        [0.20,  0.50,     0.45,       0.40,    0.65,         1.00]   # Базова_Оцінка
    ]
    
    # 4. Визначаємо стандартні відхилення
    std_devs = [
        12,    # Вік
        0.4,   # ЛогДохід (контролює "хвіст")
        0.3,   # ЛогВитрати
        5,     # Кількість_покупок
        20,    # Час_на_сайті_хв
        0.5    # Базова_Оцінка
    ]
    
    # 5. Розраховуємо коваріаційну матрицю
    cov_matrix = np.zeros((num_vars, num_vars))
    for i in range(num_vars):
        for j in range(num_vars):
            cov_matrix[i, j] = corr_matrix[i][j] * std_devs[i] * std_devs[j]
            
    # 6. ГЕНЕРАЦІЯ базових "нормальних" даних
    data = np.random.multivariate_normal(means, cov_matrix, num_samples)
    
    # 7. Конвертуємо у DataFrame
    df = pd.DataFrame(data, columns=[
        'Вік', 'Лог_Дохід', 'Лог_Витрати', 'Кількість_покупок', 'Час_на_сайті_хв', 'Базова_Оцінка'
    ])
    
    # 8. --- ПЕРЕТВОРЕННЯ ДАНИХ (РОБИМО ЇХ РЕАЛІСТИЧНИМИ) ---
    
    # Вік: робимо цілим і обрізаємо нереалістичні значення
    # ВИПРАВЛЕНО: .astype(int) видалено
    df['Вік'] = df['Вік'].round(0).clip(18, 75)
    
    # Дохід/Витрати: перетворюємо з логарифму в реальні гроші (це створює асиметрію)
    # ВИПРАВЛЕНО: .astype(int) видалено
    df['Дохід'] = np.exp(df['Лог_Дохід']).round(0)
    df['Витрати'] = np.exp(df['Лог_Витрати']).round(0)
    
    # Кількість_покупок: ціле число, мінімум 1
    # ВИПРАВЛЕНО: .astype(int) видалено
    df['Кількість_покупок'] = df['Кількість_покупок'].round(0).clip(1, 50)
    
    # Час_на_сайті_хв: ціле число, мінімум 5 хв
    # ВИПРАВЛЕНО: .astype(int) видалено
    df['Час_на_сайті_хв'] = df['Час_на_сайті_хв'].round(0).clip(5, 120)

    # Оцінка_задоволеності: НЕ-ЛІНІЙНИЙ зв'язок
    # Зв'язок з 'Часом' - логарифмічний (спочатку зростає швидко, потім повільно)
    # Додаємо трохи випадкового "шуму"
    noise = np.random.normal(0, 0.2, num_samples) # Додатковий шум
    df['Оцінка_задоволеності'] = (
        df['Базова_Оцінка'] + 
        np.log1p(df['Час_на_сайті_хв'] / 10) * 0.3 + # Нелінійний вплив часу
        noise
    ).round(1).clip(1.0, 5.0) # Обрізаємо за шкалою 1-5

    # 9. "Забруднюємо" дані для експерименту
    
    # Додаємо ID
    df.insert(0, 'ID', range(1, num_samples + 1))
    
    # Додаємо нечислову колонку
    categories = ['Постійний', 'Новий', 'VIP']
    df['Категорія_клієнта'] = [random.choice(categories) for _ in range(num_samples)]
    
    # Додаємо пропуски (NaN)
    for col in ['Дохід', 'Витрати']:
        for _ in range(int(num_samples * 0.05)): # ~5% пропусків
            df.loc[random.randint(0, num_samples-1), col] = np.nan
            
    # Видаляємо проміжні колонки
    df = df.drop(columns=['Лог_Дохід', 'Лог_Витрати', 'Базова_Оцінка'])
    
    # Повертаємо фінальний DataFrame
    return df[['ID', 'Вік', 'Дохід', 'Витрати', 'Кількість_покупок', 'Час_на_сайті_хв', 'Оцінка_задоволеності', 'Категорія_клієнта']]

# --- Головна частина скрипту ---
if __name__ == "__main__":
    file_name = "real_world_data.csv"
    
    try:
        print("Генерація реалістичних даних (v3.1, з асиметрією та нелінійними зв'язками)...")
        dataset = generate_realistic_data(num_samples=200)
        
        # Зберігаємо у файл
        dataset.to_csv(file_name, index=False, encoding='utf-8')
        
        print(f"Файл '{file_name}' успішно створено.")
        print("Тепер дані мають асиметричний розподіл (як у житті) та нелінійні зв'язки.")
        print("\nЗапустіть 'correlation_analyzer_themed.py' і завантажте цей новий файл.")
        print("Зверніть увагу, як зміняться коефіцієнти Пірсона!")

    except Exception as e:
        print(f"Сталася помилка: {e}")
        print("Переконайтеся, що у вас встановлені бібліотеки 'pandas' та 'numpy'.")
        print("Виконайте: pip install pandas numpy")

